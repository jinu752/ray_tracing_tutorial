{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpyqwPNmr6hQ"
   },
   "source": [
    "# 11 Defocus Blur - PyTorch\n",
    "\n",
    "* 기존 예제에서 for loop을 제거하고 PyTorch로 가속한 예제입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "boVrqZiSwJJx"
   },
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import sys\n",
    "from typing import List\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "infinity = sys.float_info.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9VkSbmyX1dVY"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "elif torch.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")   \n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WT0V58UVwU61"
   },
   "outputs": [],
   "source": [
    "def blend(color1: torch.Tensor, color2: torch.Tensor, t_map: torch.Tensor) -> torch.Tensor:\n",
    "    return (1.0 - t_map) * color1 + t_map * color2\n",
    "\n",
    "\n",
    "def dot(v1: torch.Tensor, v2: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.sum(v1 * v2, dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "def linear_to_gamma(linear_component: torch.Tensor) -> torch.Tensor:\n",
    "    return torch.where(linear_component > 0, torch.sqrt(linear_component), linear_component)\n",
    "\n",
    "\n",
    "def scale_color(color: torch.Tensor, num_sample_per_pixel: int):\n",
    "    scale = 1.0 / num_sample_per_pixel\n",
    "    return torch.clamp(scale * color, 0.0, 0.999)\n",
    "\n",
    "\n",
    "def rand_uniform(low: float, high: float, size: int | list | tuple, device: torch.device) -> torch.Tensor:\n",
    "    return low + (high - low) * torch.rand(size, device=device)\n",
    "\n",
    "\n",
    "def random_in_unit_sphere(width: int, height: int, samples: int, device: torch.device) -> torch.Tensor:\n",
    "    p = rand_uniform(low=-1.0, high=1.0, size=[height, width, samples, 3], device=device)\n",
    "    return f.normalize(p, dim=-1)\n",
    "\n",
    "\n",
    "def random_in_unit_disk(width: int, height: int, samples: int, device: torch.device) -> torch.Tensor:\n",
    "    p = rand_uniform(low=-1.0, high=1.0, size=[height, width, samples, 2], device=device)\n",
    "    length = torch.norm(p, dim=-1, keepdim=True)\n",
    "    p = torch.where(length > 1.0, p / length, p)    \n",
    "    return p\n",
    "\n",
    "\n",
    "def near_zero(vec_map: torch.Tensor, eps: float =1e-6) -> torch.Tensor:\n",
    "    return torch.all(torch.abs(vec_map) < eps, dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "def reflect(vec_map: torch.Tensor, normal_map: torch.Tensor) -> torch.Tensor:\n",
    "    return vec_map - 2.0 * dot(vec_map, normal_map) * normal_map\n",
    "\n",
    "\n",
    "def refract(vec_map: torch.Tensor, normal_map: torch.Tensor, etai_over_etat_map: torch.Tensor) -> torch.Tensor:\n",
    "    device = vec_map.device\n",
    "    one = torch.ones(1, device=device)\n",
    "    cos_thera_map = torch.minimum(-dot(vec_map, normal_map), one)\n",
    "    r_out_perp_map = etai_over_etat_map * (vec_map + cos_thera_map * normal_map)\n",
    "    r_out_parallel_map = -torch.sqrt(torch.abs(1.0 - dot(r_out_perp_map, r_out_perp_map))) * normal_map\n",
    "    return r_out_perp_map + r_out_parallel_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "dv_poL4zxpv3"
   },
   "outputs": [],
   "source": [
    "class Interval:\n",
    "    def __init__(self, min_map: torch.Tensor, max_map: torch.Tensor, device: torch.device):\n",
    "        if isinstance(min_map, torch.Tensor):\n",
    "            self.min_map = min_map\n",
    "        else:\n",
    "            self.min_map = torch.tensor(min_map, device=device)\n",
    "\n",
    "        if isinstance(max_map, torch.Tensor):\n",
    "            self.max_map = max_map\n",
    "        else:\n",
    "            self.max_map = torch.tensor(max_map, device=device)\n",
    "\n",
    "    def size(self) -> torch.Tensor:\n",
    "        return self.max_max - self.min_map\n",
    "\n",
    "    def contains(self, x_map: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.logical_and(self.min_map <= x_map, x_map <= self.max_map)\n",
    "\n",
    "    def surrounds(self, x_map: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.logical_and(self.min_map < x_map, x_map < self.max_map)\n",
    "\n",
    "    def clamp(self, x_map: torch.Tensor) -> torch.Tensor:\n",
    "        return torch.clamp(x_map, self.min_map, self.max_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "JSWPSlVix7xR"
   },
   "outputs": [],
   "source": [
    "class Ray:\n",
    "    def __init__(self, origin: torch.Tensor, direction_map: torch.Tensor) -> None:\n",
    "        self.origin = origin\n",
    "        self.direction_map = f.normalize(direction_map, dim=-1)\n",
    "        self.height, self.width, self.num_sample_per_pixel = self.direction_map.shape[:3]\n",
    "\n",
    "    def at(self, t_map: torch.Tensor) -> torch.Tensor:\n",
    "        return self.origin + t_map * self.direction_map\n",
    "\n",
    "    def get_device(self) -> torch.device:\n",
    "        return self.origin.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "fbEXZ-_jv4bK"
   },
   "outputs": [],
   "source": [
    "class Material:\n",
    "    def scatter(self, r_in: Ray, hit_record: \"HitRecord\") -> torch.Tensor:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "nsTRuBL4_3sZ"
   },
   "outputs": [],
   "source": [
    "class Lambertian(Material):\n",
    "    def __init__(self, albedo: torch.Tensor):\n",
    "        self.albedo = albedo\n",
    "\n",
    "    def scatter(self, r_in: Ray, hit_record: \"HitRecord\") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        device = r_in.get_device()\n",
    "\n",
    "        scatter_direction_map = (\n",
    "            hit_record.normal_map + random_in_unit_sphere(r_in.width, r_in.height, r_in.num_sample_per_pixel, device=device)\n",
    "        )\n",
    "        scattered_ray = Ray(origin=hit_record.point_map, direction_map=scatter_direction_map)\n",
    "        return self.albedo, scattered_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F_tkbif7BjJO"
   },
   "outputs": [],
   "source": [
    "class Metal(Material):\n",
    "    def __init__(self, albedo: torch.Tensor, fuzz: float):\n",
    "        self.albedo = albedo\n",
    "        self.fuzz = fuzz if fuzz < 1 else 1\n",
    "\n",
    "    def scatter(self, r_in: Ray, hit_record: \"HitRecord\") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        device = r_in.get_device()\n",
    "\n",
    "        reflected_map = reflect(r_in.direction_map, hit_record.normal_map)\n",
    "        reflected_map = (\n",
    "            f.normalize(reflected_map, dim=-1) +\n",
    "             (self.fuzz * random_in_unit_sphere(r_in.width, r_in.height, r_in.num_sample_per_pixel, device=device))\n",
    "        )\n",
    "        scattered_ray = Ray(origin=hit_record.point_map, direction_map=reflected_map)\n",
    "        return self.albedo, scattered_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "I59MJDPv2Nei"
   },
   "outputs": [],
   "source": [
    "class Dielectric(Material):\n",
    "    def __init__(self, index_of_refraction: float):\n",
    "        self.index_of_refraction = index_of_refraction\n",
    "\n",
    "    def scatter(self, r_in: Ray, hit_record: \"HitRecord\") -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        device = r_in.get_device()\n",
    "\n",
    "        attenuation = torch.tensor([1.0, 1.0, 1.0], device=device)\n",
    "        refraction_ratio_map = torch.where(hit_record.is_front_face, 1.0 / self.index_of_refraction, self.index_of_refraction)\n",
    "\n",
    "        unit_direction_map = f.normalize(r_in.direction_map, dim=-1)\n",
    "        refracted_map = refract(unit_direction_map, hit_record.normal_map, refraction_ratio_map)\n",
    "\n",
    "        scattered_ray = Ray(origin=hit_record.point_map, direction_map=refracted_map)\n",
    "        return attenuation, scattered_ray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ysxjGAqHybiR"
   },
   "outputs": [],
   "source": [
    "class HitRecord:\n",
    "    def __init__(\n",
    "        self,\n",
    "        point_map: torch.Tensor,\n",
    "        normal_map: torch.Tensor,\n",
    "        t_map: torch.Tensor,\n",
    "        valid_map: torch.Tensor,\n",
    "    ) -> None:\n",
    "        self.point_map = point_map\n",
    "        self.normal_map = normal_map\n",
    "        self.t_map = t_map\n",
    "        self.valid_map = valid_map\n",
    "        self.scattered_ray = None\n",
    "        self.albedo_map = None\n",
    "\n",
    "    def set_face_normal(self, ray: Ray, outward_normal_map: torch.Tensor) -> None:\n",
    "        self.is_front_face = dot(ray.direction_map, outward_normal_map) < 0.0\n",
    "        self.normal_map = torch.where(\n",
    "            self.is_front_face, outward_normal_map, -outward_normal_map\n",
    "        )\n",
    "\n",
    "    def update(self, other: HitRecord) -> None:\n",
    "        self.point_map = torch.where(other.valid_map, other.point_map, self.point_map)\n",
    "        self.normal_map = torch.where(other.valid_map, other.normal_map, self.normal_map)\n",
    "        self.t_map = torch.where(other.valid_map, other.t_map, self.t_map)\n",
    "        self.valid_map = torch.where(other.valid_map, other.valid_map, self.valid_map)\n",
    "\n",
    "        self.scattered_ray.origin = torch.where(\n",
    "            other.valid_map, other.scattered_ray.origin, self.scattered_ray.origin\n",
    "        )\n",
    "        self.scattered_ray.direction_map = torch.where(\n",
    "            other.valid_map, other.scattered_ray.direction_map, self.scattered_ray.direction_map\n",
    "        )\n",
    "        self.albedo_map = torch.where(other.valid_map, other.albedo_map, self.albedo_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_jX9kdFVysu5"
   },
   "outputs": [],
   "source": [
    "class Hittable:\n",
    "    def hit(self, ray: Ray, ray_t: Interval) -> HitRecord:\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "t-4UEcrPyuqD"
   },
   "outputs": [],
   "source": [
    "class Sphere(Hittable):\n",
    "    def __init__(self, center: torch.Tensor, radius: float, material: Material) -> None:\n",
    "        self.center = center\n",
    "        self.radius = radius\n",
    "        self.material = material\n",
    "\n",
    "    def hit(self, ray: Ray, ray_t: Interval) -> torch.Tensor:\n",
    "        dir_center_to_origin = ray.origin - self.center\n",
    "\n",
    "        a_map = dot(ray.direction_map, ray.direction_map)\n",
    "        half_b_map = dot(dir_center_to_origin, ray.direction_map)\n",
    "        c_map = dot(dir_center_to_origin, dir_center_to_origin) - self.radius**2.0\n",
    "\n",
    "        discriminant_map = half_b_map**2 - a_map * c_map\n",
    "        cond_discriminant = discriminant_map >= 0.0\n",
    "\n",
    "        safe_discriminant_map = torch.where(cond_discriminant, discriminant_map, 0.0)\n",
    "\n",
    "        sqrt_d_map = torch.sqrt(safe_discriminant_map)\n",
    "\n",
    "        # find the nearest root that lies in the acceptable range.\n",
    "        t_map1 = (-half_b_map - sqrt_d_map) / a_map\n",
    "        cond1 = ray_t.surrounds(t_map1)\n",
    "        t_map2 = (-half_b_map + sqrt_d_map) / a_map\n",
    "        cond2 = ray_t.surrounds(t_map2)\n",
    "\n",
    "        valid_map = torch.logical_and(cond_discriminant, torch.logical_or(cond1, cond2))\n",
    "\n",
    "        t_map = torch.where(cond1, t_map1, t_map2)\n",
    "\n",
    "        point_map = ray.at(t_map)\n",
    "        outward_normal_map = (point_map - self.center) / self.radius\n",
    "        hit_record = HitRecord(\n",
    "            point_map=point_map,\n",
    "            normal_map=outward_normal_map,\n",
    "            t_map=t_map,\n",
    "            valid_map=valid_map,\n",
    "        )\n",
    "        hit_record.set_face_normal(ray=ray, outward_normal_map=outward_normal_map)\n",
    "\n",
    "        albedo, scattered_ray = self.material.scatter(r_in=ray, hit_record=hit_record)\n",
    "        hit_record.scattered_ray = scattered_ray\n",
    "        hit_record.albedo_map = albedo\n",
    "\n",
    "        return hit_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "4AeUkjJPy6Xd"
   },
   "outputs": [],
   "source": [
    "class HittableList(Hittable):\n",
    "    def __init__(self) -> None:\n",
    "        self.objects: List[Hittable] = []\n",
    "\n",
    "    def clear(self) -> None:\n",
    "        self.objects.clear()\n",
    "\n",
    "    def add(self, object: Hittable) -> None:\n",
    "        self.objects.append(object)\n",
    "\n",
    "    def hit(self, ray: Ray, ray_t: Interval) -> HitRecord:\n",
    "        device = ray.get_device()\n",
    "\n",
    "        record = None\n",
    "        closest_so_far_map = ray_t.max_map\n",
    "\n",
    "        for object in self.objects:\n",
    "            tmp_record = object.hit(\n",
    "                ray=ray, ray_t=Interval(ray_t.min_map, closest_so_far_map, device)\n",
    "            )\n",
    "            closest_so_far_map = torch.where(\n",
    "                tmp_record.valid_map, tmp_record.t_map, closest_so_far_map\n",
    "            )\n",
    "\n",
    "            if record is None:\n",
    "                record = tmp_record\n",
    "            else:\n",
    "                record.update(tmp_record)\n",
    "\n",
    "        return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "vopCkGdwzFJy"
   },
   "outputs": [],
   "source": [
    "def ray_color(ray: Ray, world: Hittable, depth: int) -> torch.Tensor:\n",
    "    device = ray.get_device()\n",
    "\n",
    "    color1 = torch.tensor([1.0, 1.0, 1.0], device=device)\n",
    "    color2 = torch.tensor([0.5, 0.7, 1.0], device=device)\n",
    "\n",
    "    world_color = torch.zeros([3], device=device)\n",
    "\n",
    "    color_map = None\n",
    "    curr_ray = ray\n",
    "    diffuse_att = 1.0\n",
    "\n",
    "    prev_valid_map = None\n",
    "\n",
    "    for d in tqdm(range(depth)):\n",
    "        if d > 0:\n",
    "            curr_ray = record.scattered_ray\n",
    "\n",
    "        t_map = 0.5 * (curr_ray.direction_map[..., 1:2] + 1.0)\n",
    "        curr_background_color = diffuse_att * blend(color1=color1, color2=color2, t_map=t_map)\n",
    "\n",
    "        record = world.hit(ray=curr_ray, ray_t=Interval(min_map=0.001, max_map=infinity, device=device))\n",
    "\n",
    "        # prev_valid and record_valid: 0\n",
    "        # prev_valid and !record_valid: d_att * background_color\n",
    "        # prev_valid! and !record_valid: prev_color\n",
    "        # prev_valid! and record_valid: can not happen\n",
    "\n",
    "        if prev_valid_map is not None:\n",
    "            curr_valid_map = prev_valid_map * record.valid_map\n",
    "            curr_background_color = torch.where(prev_valid_map, curr_background_color, color_map)\n",
    "        else:\n",
    "            curr_valid_map = record.valid_map\n",
    "\n",
    "        color_map = torch.where(curr_valid_map, world_color, curr_background_color)\n",
    "        diffuse_att = diffuse_att * record.albedo_map\n",
    "\n",
    "        prev_valid_map = curr_valid_map\n",
    "\n",
    "    return color_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "IT6WFZhH5cKM"
   },
   "outputs": [],
   "source": [
    "def get_uv_map(\n",
    "        image_width: int, \n",
    "        image_height: int, \n",
    "        num_sample_per_pixel: int, \n",
    "        device: torch.device\n",
    "    ) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "    us = torch.arange(start=0, end=image_width, device=device) + 0.5\n",
    "    vs = torch.arange(start=0, end=image_height, device=device) + 0.5\n",
    "    u_map, v_map = torch.meshgrid(us, vs, indexing=\"xy\")\n",
    "    u_map = u_map[..., np.newaxis, np.newaxis]\n",
    "    v_map = v_map[..., np.newaxis, np.newaxis]\n",
    "\n",
    "    u_jitter = rand_uniform(low=0.0, high=1.0,\n",
    "                            size=[image_height, image_width, num_sample_per_pixel, 1],\n",
    "                            device=device)\n",
    "    v_jitter = rand_uniform(low=0.0, high=1.0,\n",
    "                            size=[image_height, image_width, num_sample_per_pixel, 1],\n",
    "                            device=device)\n",
    "\n",
    "    u_map = u_map + u_jitter\n",
    "    v_map = v_map + v_jitter\n",
    "    return u_map, v_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "853ovcr934Kk"
   },
   "outputs": [],
   "source": [
    "class Camera:\n",
    "    def __init__(\n",
    "            self,\n",
    "            aspect_ratio: float, \n",
    "            image_width: int,             \n",
    "            num_sample_per_pixel: int,\n",
    "            max_depth: int,\n",
    "            vfov: float,\n",
    "            lookfrom: torch.Tensor,\n",
    "            lookat: torch.Tensor,\n",
    "            vup: torch.Tensor,\n",
    "            defocus_angle: float,\n",
    "            focus_dist: float,\n",
    "            device: torch.device,\n",
    "        ) -> None:\n",
    "        self.aspect_ratio = aspect_ratio\n",
    "        self.image_width = image_width\n",
    "        self.num_sample_per_pixel = num_sample_per_pixel\n",
    "        self.max_depth = max_depth\n",
    "        self.vfov = vfov\n",
    "        self.device = device\n",
    "        self.lookfrom = lookfrom\n",
    "        self.lookat = lookat\n",
    "        self.vup = vup\n",
    "        self.defocus_angle = defocus_angle\n",
    "        self.focus_dist = focus_dist\n",
    "        \n",
    "    def _prepare(self):\n",
    "        self.image_height = int(self.image_width / self.aspect_ratio)\n",
    "        self.image_height = 1 if self.image_height < 1 else self.image_height\n",
    "\n",
    "        self.center = self.lookfrom\n",
    "        \n",
    "        theta = np.radians(self.vfov)\n",
    "        h = np.tan(theta / 2.0)\n",
    "        viewport_height = 2.0 * h * self.focus_dist\n",
    "        viewport_width = self.aspect_ratio * viewport_height\n",
    "\n",
    "        w = f.normalize(self.lookfrom - self.lookat, dim=-1)\n",
    "        u = f.normalize(torch.cross(self.vup, w, dim=-1), dim=-1)\n",
    "        v = torch.cross(w, u, dim=-1)\n",
    "\n",
    "        self.horizontal_vec = viewport_width * u\n",
    "        self.vertical_vec = viewport_height * v\n",
    "        self.frontal_vec = self.focus_dist * w\n",
    "        self.lower_left_corner = (\n",
    "            self.center\n",
    "            - self.horizontal_vec / 2.0\n",
    "            - self.vertical_vec / 2.0\n",
    "            - self.frontal_vec\n",
    "        )\n",
    "\n",
    "        self.pixel_delta_u = self.horizontal_vec / self.image_width\n",
    "        self.pixel_delta_v = self.vertical_vec / self.image_height\n",
    "\n",
    "        defocus_radius = self.focus_dist * np.tan(np.radians(self.defocus_angle / 2.0))\n",
    "        self.defocus_disk_u = u * defocus_radius\n",
    "        self.defocus_disk_v = v * defocus_radius\n",
    "\n",
    "    def _defocus_disk_sample(self):\n",
    "        p = random_in_unit_disk(self.image_width, self.image_height, self.num_sample_per_pixel, self.device)\n",
    "        return self.center + p[..., 0:1] * self.defocus_disk_u + p[..., 1:2] * self.defocus_disk_v\n",
    "\n",
    "    def _get_ray(self, u_map: torch.Tensor, v_map: torch.Tensor) -> Ray:\n",
    "        ray_origin = self.center if (self.defocus_angle < 0) else self._defocus_disk_sample()\n",
    "        pixel_sample = self.lower_left_corner + u_map * self.pixel_delta_u + v_map * self.pixel_delta_v\n",
    "\n",
    "        return Ray(origin=ray_origin, direction_map=pixel_sample - ray_origin)\n",
    "    \n",
    "    def render(self, world: HittableList) -> torch.Tensor:\n",
    "        with torch.no_grad():\n",
    "            self._prepare()\n",
    "            \n",
    "            u_map, v_map = get_uv_map(\n",
    "                self.image_width, \n",
    "                self.image_height, \n",
    "                self.num_sample_per_pixel, \n",
    "                device=self.device\n",
    "            )\n",
    "            ray = self._get_ray(u_map=u_map, v_map=v_map)\n",
    "\n",
    "            color_map = ray_color(ray=ray, world=world, depth=self.max_depth)\n",
    "            color_map = torch.sum(color_map, dim=2)\n",
    "            image = scale_color(color_map, num_sample_per_pixel=self.num_sample_per_pixel)\n",
    "            image = linear_to_gamma(image)\n",
    "        return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "byNftoQSIMTF"
   },
   "outputs": [],
   "source": [
    "# material\n",
    "material_ground = Lambertian(torch.tensor([0.8, 0.8, 0.0], device=device))\n",
    "material_center = Lambertian(torch.tensor([0.1, 0.2, 0.5], device=device))\n",
    "material_left = Dielectric(1.5)\n",
    "material_bubble = Dielectric(1.0 / 1.5)\n",
    "material_right = Metal(torch.tensor([0.8, 0.6, 0.2], device=device), fuzz=1.0)\n",
    "\n",
    "# world\n",
    "world = HittableList()\n",
    "world.add(Sphere(center=torch.tensor([0.0, -100.5, -1.0], device=device), radius=100.0, material=material_ground))\n",
    "world.add(Sphere(center=torch.tensor([0.0, 0.0, -1.2], device=device), radius=0.5, material=material_center))\n",
    "world.add(Sphere(center=torch.tensor([-1.0, 0.0, -1.0], device=device), radius=0.5, material=material_left))\n",
    "world.add(Sphere(center=torch.tensor([-1.0, 0.0, -1.0], device=device), radius=0.4, material=material_bubble))\n",
    "world.add(Sphere(center=torch.tensor([ 1.0, 0.0, -1.0], device=device), radius=0.5, material=material_right))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera = Camera(\n",
    "    aspect_ratio = 16.0 / 9.0,\n",
    "    image_width = 400,    \n",
    "    num_sample_per_pixel = 100,\n",
    "    max_depth = 50,    \n",
    "    vfov = 20.0,  # vertical view angle (field of view)    \n",
    "    lookfrom = torch.tensor([-2.0, 2.0, 1.0], device=device),\n",
    "    lookat = torch.tensor([0.0, 0.0, -1.0], device=device),\n",
    "    vup = torch.tensor([0.0, 1.0, 0.0], device=device),\n",
    "    defocus_angle = 10.0,\n",
    "    focus_dist = 3.4,\n",
    "    device = device,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7665,
     "status": "ok",
     "timestamp": 1731512832891,
     "user": {
      "displayName": "Jinwoo Lee",
      "userId": "12336114295707154907"
     },
     "user_tz": -540
    },
    "id": "fTfqwIghINUd",
    "outputId": "65c302b2-e092-4116-a55b-b61aa4dbf09c"
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "image = camera.render(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 339
    },
    "executionInfo": {
     "elapsed": 976,
     "status": "ok",
     "timestamp": 1731512833866,
     "user": {
      "displayName": "Jinwoo Lee",
      "userId": "12336114295707154907"
     },
     "user_tz": -540
    },
    "id": "mX3uXK9PIONp",
    "outputId": "6ec79fce-b909-4abb-e30a-fc897dc79d1c"
   },
   "outputs": [],
   "source": [
    "if image.get_device() == 0:\n",
    "    image_np = image.cpu().numpy()\n",
    "else:\n",
    "    image_np = image.numpy()\n",
    "\n",
    "plt.imshow(image_np, origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = HittableList()\n",
    "\n",
    "# ground\n",
    "material_ground = Lambertian(torch.tensor([0.5, 0.5, 0.5], device=device))\n",
    "world.add(Sphere(center=torch.tensor([0.0, -1000.0, 0.0], device=device), radius=1000.0, material=material_ground))\n",
    "\n",
    "for a in range(-11, 11):\n",
    "    for b in range(-11, 11):\n",
    "        choose_mat = rand_uniform(0.0, 1.0, size=1, device=device)\n",
    "        center = torch.tensor(\n",
    "            [a + 0.9 * rand_uniform(0.0, 1.0, size=1, device=device), \n",
    "             0.2, \n",
    "             b + 0.9 * rand_uniform(0.0, 1.0, size=1, device=device)], \n",
    "            device=device\n",
    "        )\n",
    "\n",
    "        if torch.norm(center - torch.tensor([4.0, 0.2, 0.0], device=device)) > 0.9:\n",
    "            if choose_mat < 0.8:\n",
    "                # diffuse\n",
    "                albedo = rand_uniform(0.0, 1.0, size=3, device=device) * rand_uniform(0.0, 1.0, size=3, device=device)\n",
    "                material_sphere = Lambertian(albedo)\n",
    "                world.add(Sphere(center=center, radius=0.2, material=material_sphere))\n",
    "            elif choose_mat < 0.95:                    \n",
    "                # metal\n",
    "                albedo = rand_uniform(0.5, 1.0, size=3, device=device)\n",
    "                fuzz = rand_uniform(0.0, 0.5, size=1, device=device)\n",
    "                material_sphere = Metal(albedo, fuzz)\n",
    "                world.add(Sphere(center=center, radius=0.2, material=material_sphere))\n",
    "            else:\n",
    "                # glass\n",
    "                material_sphere = Dielectric(1.5)\n",
    "                world.add(Sphere(center=center, radius=0.2, material=material_sphere))\n",
    "                \n",
    "material1 = Dielectric(1.5)\n",
    "world.add(Sphere(center=torch.tensor([0.0, 1.0, 0.0], device=device), radius=1.0, material=material1))\n",
    "\n",
    "material2 = Lambertian(torch.tensor([0.4, 0.2, 0.1], device=device))\n",
    "world.add(Sphere(center=torch.tensor([-4.0, 1.0, 0.0], device=device), radius=1.0, material=material2))\n",
    "\n",
    "material3 = Metal(torch.tensor([0.7, 0.6, 0.5], device=device), fuzz=0.0)\n",
    "world.add(Sphere(center=torch.tensor([4.0, 1.0, 0.0], device=device), radius=1.0, material=material3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.aspect_ratio = 16.0 / 9.0\n",
    "camera.image_width = 400\n",
    "camera.num_sample_per_pixel = 100\n",
    "camera.max_depth = 50\n",
    "\n",
    "camera.vfov = 20\n",
    "camera.lookfrom = torch.tensor([13.0, 2.0, 3.0], device=device)\n",
    "camera.lookat = torch.tensor([0.0, 0.0, 0.0], device=device)\n",
    "camera.vup = torch.tensor([0.0, 1.0, 0.0], device=device)\n",
    "camera.defocus_angle = 0.6\n",
    "camera.focus_dist = 10.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "image = camera.render(world)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if image.get_device() == 0:\n",
    "    image_np = image.cpu().numpy()\n",
    "else:\n",
    "    image_np = image.numpy()\n",
    "\n",
    "plt.imshow(image_np, origin=\"lower\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyO0GZH4gvah1q1nY5u0q8ct",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
